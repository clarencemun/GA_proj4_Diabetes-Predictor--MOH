{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with TensorFlow\n",
    "\n",
    "1. **Import necessary TensorFlow modules.**\n",
    "2. **Define the model architecture.** Assuming a simple architecture with two hidden layers.\n",
    "3. **Compile the model** with an appropriate optimizer, loss function, and metrics.\n",
    "4. **Prepare the data** similarly to how it's prepared for the `MLPClassifier`, ensuring input features are correctly scaled and split into training and test sets.\n",
    "5. **Train the model** on the data.\n",
    "\n",
    "Note the following:\n",
    "\n",
    "- **Architecture**: This example uses two dense layers with 128 and 64 units, respectively, and ReLU activation functions. The output layer uses a sigmoid activation function for binary classification. Adjust the layer sizes and quantities to match your specific needs or the original `MLPClassifier` configuration.\n",
    "- **Compilation**: The model is compiled with the Adam optimizer and binary cross-entropy loss, which are standard for binary classification tasks.\n",
    "- **Training**: The model is trained for 100 epochs with a validation split. Adjust the number of epochs and validation split according to your specific requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clarencemun/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-04-11 14:13:36.155348: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-04-11 14:13:36.155370: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-04-11 14:13:36.155375: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-04-11 14:13:36.155775: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-11 14:13:36.155809: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 14:13:36.701473: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.5264 - recall: 0.7811 - val_loss: 0.5056 - val_recall: 0.7929\n",
      "Epoch 2/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.5018 - recall: 0.8043 - val_loss: 0.5101 - val_recall: 0.8332\n",
      "Epoch 3/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.5005 - recall: 0.8016 - val_loss: 0.5053 - val_recall: 0.8332\n",
      "Epoch 4/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.4951 - recall: 0.8074 - val_loss: 0.5021 - val_recall: 0.7879\n",
      "Epoch 5/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.4923 - recall: 0.8051 - val_loss: 0.5033 - val_recall: 0.8022\n",
      "Epoch 6/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 0.4938 - recall: 0.8093 - val_loss: 0.5029 - val_recall: 0.7952\n",
      "Epoch 7/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.4904 - recall: 0.8060 - val_loss: 0.5034 - val_recall: 0.7964\n",
      "Epoch 8/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.4877 - recall: 0.8062 - val_loss: 0.5031 - val_recall: 0.7792\n",
      "Epoch 9/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.4845 - recall: 0.8064 - val_loss: 0.5047 - val_recall: 0.8003\n",
      "Epoch 10/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.4858 - recall: 0.8064 - val_loss: 0.5065 - val_recall: 0.8091\n",
      "Epoch 11/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.4793 - recall: 0.8128 - val_loss: 0.5108 - val_recall: 0.7688\n",
      "Epoch 12/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.4811 - recall: 0.8076 - val_loss: 0.5077 - val_recall: 0.8098\n",
      "Epoch 13/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.4736 - recall: 0.8111 - val_loss: 0.5132 - val_recall: 0.7550\n",
      "Epoch 14/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.4769 - recall: 0.8043 - val_loss: 0.5152 - val_recall: 0.8019\n",
      "Epoch 15/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.4719 - recall: 0.8094 - val_loss: 0.5141 - val_recall: 0.7983\n",
      "Epoch 16/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.4701 - recall: 0.8069 - val_loss: 0.5163 - val_recall: 0.7838\n",
      "Epoch 17/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.4680 - recall: 0.8109 - val_loss: 0.5210 - val_recall: 0.8001\n",
      "Epoch 18/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.4632 - recall: 0.8068 - val_loss: 0.5190 - val_recall: 0.7906\n",
      "Epoch 19/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.4614 - recall: 0.8088 - val_loss: 0.5269 - val_recall: 0.7308\n",
      "Epoch 20/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.4575 - recall: 0.8126 - val_loss: 0.5259 - val_recall: 0.7775\n",
      "Epoch 21/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.4575 - recall: 0.8092 - val_loss: 0.5310 - val_recall: 0.7723\n",
      "Epoch 22/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.4547 - recall: 0.8074 - val_loss: 0.5317 - val_recall: 0.7645\n",
      "Epoch 23/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.4522 - recall: 0.8105 - val_loss: 0.5333 - val_recall: 0.7525\n",
      "Epoch 24/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.4476 - recall: 0.8114 - val_loss: 0.5386 - val_recall: 0.7766\n",
      "Epoch 25/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.4469 - recall: 0.8122 - val_loss: 0.5389 - val_recall: 0.7559\n",
      "Epoch 26/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.4462 - recall: 0.8152 - val_loss: 0.5439 - val_recall: 0.7508\n",
      "Epoch 27/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 0.4437 - recall: 0.8101 - val_loss: 0.5453 - val_recall: 0.7773\n",
      "Epoch 28/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.4378 - recall: 0.8212 - val_loss: 0.5551 - val_recall: 0.7883\n",
      "Epoch 29/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.4365 - recall: 0.8184 - val_loss: 0.5517 - val_recall: 0.7322\n",
      "Epoch 30/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.4339 - recall: 0.8156 - val_loss: 0.5575 - val_recall: 0.7684\n",
      "Epoch 31/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.4300 - recall: 0.8168 - val_loss: 0.5580 - val_recall: 0.7555\n",
      "Epoch 32/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - loss: 0.4307 - recall: 0.8165 - val_loss: 0.5577 - val_recall: 0.7451\n",
      "Epoch 33/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.4306 - recall: 0.8165 - val_loss: 0.5651 - val_recall: 0.7474\n",
      "Epoch 34/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.4243 - recall: 0.8197 - val_loss: 0.5708 - val_recall: 0.7196\n",
      "Epoch 35/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.4224 - recall: 0.8166 - val_loss: 0.5760 - val_recall: 0.7393\n",
      "Epoch 36/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.4205 - recall: 0.8178 - val_loss: 0.5747 - val_recall: 0.7408\n",
      "Epoch 37/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - loss: 0.4190 - recall: 0.8183 - val_loss: 0.5772 - val_recall: 0.7506\n",
      "Epoch 38/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.4132 - recall: 0.8178 - val_loss: 0.5809 - val_recall: 0.7541\n",
      "Epoch 39/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.4162 - recall: 0.8167 - val_loss: 0.5879 - val_recall: 0.7403\n",
      "Epoch 40/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.4073 - recall: 0.8253 - val_loss: 0.5904 - val_recall: 0.7829\n",
      "Epoch 41/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.4082 - recall: 0.8258 - val_loss: 0.5911 - val_recall: 0.7573\n",
      "Epoch 42/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - loss: 0.4040 - recall: 0.8236 - val_loss: 0.6005 - val_recall: 0.7308\n",
      "Epoch 43/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - loss: 0.4086 - recall: 0.8208 - val_loss: 0.6030 - val_recall: 0.6853\n",
      "Epoch 44/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - loss: 0.3996 - recall: 0.8195 - val_loss: 0.6066 - val_recall: 0.7230\n",
      "Epoch 45/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.3990 - recall: 0.8268 - val_loss: 0.6070 - val_recall: 0.7366\n",
      "Epoch 46/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.3999 - recall: 0.8234 - val_loss: 0.6087 - val_recall: 0.7315\n",
      "Epoch 47/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.3965 - recall: 0.8238 - val_loss: 0.6259 - val_recall: 0.7177\n",
      "Epoch 48/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.3947 - recall: 0.8243 - val_loss: 0.6189 - val_recall: 0.7361\n",
      "Epoch 49/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.3934 - recall: 0.8281 - val_loss: 0.6332 - val_recall: 0.7424\n",
      "Epoch 50/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.3909 - recall: 0.8306 - val_loss: 0.6281 - val_recall: 0.7347\n",
      "Epoch 51/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.3887 - recall: 0.8262 - val_loss: 0.6292 - val_recall: 0.7430\n",
      "Epoch 52/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.3827 - recall: 0.8341 - val_loss: 0.6331 - val_recall: 0.7615\n",
      "Epoch 53/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.3892 - recall: 0.8310 - val_loss: 0.6300 - val_recall: 0.7431\n",
      "Epoch 54/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 0.3798 - recall: 0.8309 - val_loss: 0.6371 - val_recall: 0.7205\n",
      "Epoch 55/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - loss: 0.3840 - recall: 0.8340 - val_loss: 0.6403 - val_recall: 0.7387\n",
      "Epoch 56/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - loss: 0.3828 - recall: 0.8320 - val_loss: 0.6434 - val_recall: 0.7056\n",
      "Epoch 57/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.3817 - recall: 0.8305 - val_loss: 0.6516 - val_recall: 0.7329\n",
      "Epoch 58/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.3773 - recall: 0.8341 - val_loss: 0.6589 - val_recall: 0.7371\n",
      "Epoch 59/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.3787 - recall: 0.8367 - val_loss: 0.6531 - val_recall: 0.7357\n",
      "Epoch 60/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3762 - recall: 0.8395 - val_loss: 0.6674 - val_recall: 0.7062\n",
      "Epoch 61/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3757 - recall: 0.8339 - val_loss: 0.6649 - val_recall: 0.7189\n",
      "Epoch 62/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3691 - recall: 0.8414 - val_loss: 0.6863 - val_recall: 0.7285\n",
      "Epoch 63/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3736 - recall: 0.8321 - val_loss: 0.6702 - val_recall: 0.7311\n",
      "Epoch 64/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3664 - recall: 0.8406 - val_loss: 0.6859 - val_recall: 0.7304\n",
      "Epoch 65/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3702 - recall: 0.8355 - val_loss: 0.6897 - val_recall: 0.7545\n",
      "Epoch 66/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3684 - recall: 0.8384 - val_loss: 0.6876 - val_recall: 0.7582\n",
      "Epoch 67/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3700 - recall: 0.8323 - val_loss: 0.6836 - val_recall: 0.7260\n",
      "Epoch 68/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3640 - recall: 0.8350 - val_loss: 0.6910 - val_recall: 0.7288\n",
      "Epoch 69/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3647 - recall: 0.8360 - val_loss: 0.6875 - val_recall: 0.7109\n",
      "Epoch 70/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3590 - recall: 0.8375 - val_loss: 0.7035 - val_recall: 0.7297\n",
      "Epoch 71/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3616 - recall: 0.8389 - val_loss: 0.7046 - val_recall: 0.7025\n",
      "Epoch 72/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3585 - recall: 0.8396 - val_loss: 0.7139 - val_recall: 0.6788\n",
      "Epoch 73/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3594 - recall: 0.8413 - val_loss: 0.7151 - val_recall: 0.6991\n",
      "Epoch 74/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3598 - recall: 0.8349 - val_loss: 0.7106 - val_recall: 0.7324\n",
      "Epoch 75/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3561 - recall: 0.8419 - val_loss: 0.7045 - val_recall: 0.6945\n",
      "Epoch 76/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3599 - recall: 0.8382 - val_loss: 0.7170 - val_recall: 0.7053\n",
      "Epoch 77/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3606 - recall: 0.8401 - val_loss: 0.7275 - val_recall: 0.7150\n",
      "Epoch 78/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3591 - recall: 0.8396 - val_loss: 0.7349 - val_recall: 0.7201\n",
      "Epoch 79/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3497 - recall: 0.8442 - val_loss: 0.7320 - val_recall: 0.6934\n",
      "Epoch 80/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3541 - recall: 0.8371 - val_loss: 0.7365 - val_recall: 0.7513\n",
      "Epoch 81/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.3474 - recall: 0.8447 - val_loss: 0.7341 - val_recall: 0.7244\n",
      "Epoch 82/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.3457 - recall: 0.8459 - val_loss: 0.7400 - val_recall: 0.7235\n",
      "Epoch 83/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.3525 - recall: 0.8391 - val_loss: 0.7460 - val_recall: 0.7462\n",
      "Epoch 84/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.3455 - recall: 0.8493 - val_loss: 0.7439 - val_recall: 0.7081\n",
      "Epoch 85/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.3480 - recall: 0.8458 - val_loss: 0.7557 - val_recall: 0.7270\n",
      "Epoch 86/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.3468 - recall: 0.8425 - val_loss: 0.7488 - val_recall: 0.7336\n",
      "Epoch 87/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.3497 - recall: 0.8446 - val_loss: 0.7593 - val_recall: 0.7209\n",
      "Epoch 88/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.3428 - recall: 0.8478 - val_loss: 0.7640 - val_recall: 0.7320\n",
      "Epoch 89/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.3423 - recall: 0.8466 - val_loss: 0.7667 - val_recall: 0.7087\n",
      "Epoch 90/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.3427 - recall: 0.8420 - val_loss: 0.7717 - val_recall: 0.7412\n",
      "Epoch 91/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.3411 - recall: 0.8447 - val_loss: 0.7769 - val_recall: 0.7239\n",
      "Epoch 92/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.3377 - recall: 0.8473 - val_loss: 0.7810 - val_recall: 0.7297\n",
      "Epoch 93/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.3369 - recall: 0.8472 - val_loss: 0.7837 - val_recall: 0.6991\n",
      "Epoch 94/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.3319 - recall: 0.8529 - val_loss: 0.7918 - val_recall: 0.7161\n",
      "Epoch 95/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.3386 - recall: 0.8474 - val_loss: 0.7908 - val_recall: 0.7465\n",
      "Epoch 96/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.3375 - recall: 0.8527 - val_loss: 0.7915 - val_recall: 0.7263\n",
      "Epoch 97/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.3359 - recall: 0.8510 - val_loss: 0.7899 - val_recall: 0.7180\n",
      "Epoch 98/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.3379 - recall: 0.8480 - val_loss: 0.7929 - val_recall: 0.6950\n",
      "Epoch 99/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.3336 - recall: 0.8479 - val_loss: 0.8017 - val_recall: 0.7440\n",
      "Epoch 100/100\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.3338 - recall: 0.8491 - val_loss: 0.7997 - val_recall: 0.7345\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.metrics import TruePositives, TrueNegatives, FalsePositives, FalseNegatives\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./data/diabetes_binary_5050split_health_indicators_BRFSS2015.csv\")\n",
    "\n",
    "# change columns to lowercase\n",
    "df.columns = df.columns.str.lower()\n",
    "df.columns\n",
    "\n",
    "# create interaction terms\n",
    "df['bmi_highbp_diffwalk_interaction'] = df['bmi'] * df['highbp'] * df['diffwalk']\n",
    "df['age_highchol_heartdiseaseorattack_interaction'] = df['age'] * df['highchol'] * df['heartdiseaseorattack']\n",
    "df['genhlth_physhlth_interaction'] = df['genhlth'] * df['physhlth']\n",
    "\n",
    "\n",
    "# Assuming df is your DataFrame and has already been loaded\n",
    "X = df.drop('diabetes_binary', axis=1).values\n",
    "y = df['diabetes_binary'].values\n",
    "\n",
    "# drop columns that are poorly correlated with 'diabetes_binary'\n",
    "df.drop(['smoker', 'fruits', 'veggies', 'hvyalcoholconsump', 'anyhealthcare', 'nodocbccost', 'menthlth', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Defining the model architecture\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))  # Using sigmoid for binary classification\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['recall'])\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabulate pre-tuning scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953us/step\n",
      "Model               Accuracy    Precision    Sensitivity    Specificity    F1-Score\n",
      "----------------  ----------  -----------  -------------  -------------  ----------\n",
      "TensorFlow Model    0.698352     0.687483        0.72726       0.669448    0.706812\n"
     ]
    }
   ],
   "source": [
    "# Initialize the list to store metric results\n",
    "metric_results = []\n",
    "\n",
    "# Assuming y_test and X_test_scaled are your test labels and features\n",
    "# First, get the model's predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_classes = (y_pred > 0.5).astype(\"int32\")\n",
    "\n",
    "# Now, compute the metrics\n",
    "tp = TruePositives()(y_test, y_pred_classes).numpy()\n",
    "tn = TrueNegatives()(y_test, y_pred_classes).numpy()\n",
    "fp = FalsePositives()(y_test, y_pred_classes).numpy()\n",
    "fn = FalseNegatives()(y_test, y_pred_classes).numpy()\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)  # Sensitivity\n",
    "specificity = tn / (tn + fp)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Assuming `metric_results` is your existing list of model performances\n",
    "metric_results.append([\"TensorFlow Model\", accuracy, precision, recall, specificity, f1_score])\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(metric_results, headers=[\"Model\", \"Accuracy\", \"Precision\", \"Sensitivity\", \"Specificity\", \"F1-Score\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning using Keras optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 02m 59s]\n",
      "val_accuracy: 0.7553708553314209\n",
      "\n",
      "Best val_accuracy So Far: 0.757050633430481\n",
      "Total elapsed time: 00h 32m 10s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 352 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.7401 - loss: 0.5229 - val_accuracy: 0.7508 - val_loss: 0.5052\n",
      "Epoch 2/10\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - accuracy: 0.7517 - loss: 0.5018 - val_accuracy: 0.7514 - val_loss: 0.5024\n",
      "Epoch 3/10\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - accuracy: 0.7526 - loss: 0.5034 - val_accuracy: 0.7517 - val_loss: 0.5028\n",
      "Epoch 4/10\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.7570 - loss: 0.4984 - val_accuracy: 0.7555 - val_loss: 0.5020\n",
      "Epoch 5/10\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - accuracy: 0.7566 - loss: 0.4995 - val_accuracy: 0.7527 - val_loss: 0.5019\n",
      "Epoch 6/10\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - accuracy: 0.7576 - loss: 0.4982 - val_accuracy: 0.7540 - val_loss: 0.5013\n",
      "Epoch 7/10\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - accuracy: 0.7586 - loss: 0.4962 - val_accuracy: 0.7521 - val_loss: 0.5017\n",
      "Epoch 8/10\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - accuracy: 0.7571 - loss: 0.4954 - val_accuracy: 0.7544 - val_loss: 0.5029\n",
      "Epoch 9/10\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - accuracy: 0.7568 - loss: 0.4974 - val_accuracy: 0.7535 - val_loss: 0.5011\n",
      "Epoch 10/10\n",
      "\u001b[1m1414/1414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.7579 - loss: 0.4942 - val_accuracy: 0.7501 - val_loss: 0.5059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3b4c88310>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_builder(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(X_train_scaled.shape[1],)))\n",
    "    \n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(tf.keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "# Create a callback to stop training early after reaching a certain value for the validation loss\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train_scaled, y_train, epochs=10, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabulate best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Model                    Accuracy    Precision    Sensitivity    Specificity    F1-Score\n",
      "---------------------  ----------  -----------  -------------  -------------  ----------\n",
      "Best HyperTuned Model    0.750336     0.732066       0.789645       0.711033    0.759766\n"
     ]
    }
   ],
   "source": [
    "# 1. Evaluate the model to get the loss and accuracy\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "# 2. Predict on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_classes = (y_pred > 0.5).astype(\"int32\")\n",
    "\n",
    "# 3. Calculate metrics\n",
    "precision = precision_score(y_test, y_pred_classes)\n",
    "recall = recall_score(y_test, y_pred_classes)  # Sensitivity\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_classes).ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "f1 = f1_score(y_test, y_pred_classes)\n",
    "\n",
    "# Prepare results for tabulation\n",
    "metric_results = [[\"Best HyperTuned Model\", test_accuracy, precision, recall, specificity, f1]]\n",
    "\n",
    "# 4. Print the table\n",
    "print(tabulate(metric_results, headers=[\"Model\", \"Accuracy\", \"Precision\", \"Sensitivity\", \"Specificity\", \"F1-Score\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run best model on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7928/7928\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df_full = pd.read_csv(\"./data/diabetes_binary_health_indicators_BRFSS2015.csv\")\n",
    "\n",
    "# Change columns to lowercase\n",
    "df_full.columns = df_full.columns.str.lower()\n",
    "\n",
    "# Create interaction terms\n",
    "df_full['bmi_highbp_diffwalk_interaction'] = df_full['bmi'] * df_full['highbp'] * df_full['diffwalk']\n",
    "df_full['age_highchol_heartdiseaseorattack_interaction'] = df_full['age'] * df_full['highchol'] * df_full['heartdiseaseorattack']\n",
    "df_full['genhlth_physhlth_interaction'] = df_full['genhlth'] * df_full['physhlth']\n",
    "\n",
    "# Drop columns that are poorly correlated with 'diabetes_binary'\n",
    "df_full.drop(['smoker', 'fruits', 'veggies', 'hvyalcoholconsump', 'anyhealthcare', 'nodocbccost', 'menthlth', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "# Assuming 'scaler' is your StandardScaler instance used previously and 'model' is your trained best model\n",
    "\n",
    "# Prepare the dataset for prediction\n",
    "X_full = df_full.drop('diabetes_binary', axis=1).values  # Use the correct case for column names\n",
    "\n",
    "# Scale the features\n",
    "X_full_scaled = scaler.transform(X_full)\n",
    "\n",
    "# Predict\n",
    "y_pred_full = model.predict(X_full_scaled)\n",
    "y_pred_classes_full = (y_pred_full > 0.5).astype(\"int32\")\n",
    "\n",
    "# Now, y_pred_classes_full contains the binary predictions for your full dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate prediction against actual value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.740062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.319432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall (Sensitivity)</td>\n",
       "      <td>0.765631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Specificity</td>\n",
       "      <td>0.735923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.450789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric     Score\n",
       "0              Accuracy  0.740062\n",
       "1             Precision  0.319432\n",
       "2  Recall (Sensitivity)  0.765631\n",
       "3           Specificity  0.735923\n",
       "4              F1-Score  0.450789"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Actual vs. Predicted\n",
    "y_true = df_full['diabetes_binary']\n",
    "y_pred = df_full['predicted_diabetes']\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)  # Also known as sensitivity\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Summarize metrics in a DataFrame for a nice table view\n",
    "import pandas as pd\n",
    "\n",
    "metrics_summary = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall (Sensitivity)\", \"Specificity\", \"F1-Score\"],\n",
    "    \"Score\": [accuracy, precision, recall, specificity, f1]\n",
    "})\n",
    "\n",
    "metrics_summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
